# Import TensorFlow library
import tensorflow as tf

# Load the data -->  Load MNIST dataset
'''
            loads the MNIST dataset using the load_data() function provided by Keras, a high level API of TensorFlow.
            The MNIST dataset contains 70,000 images of handwritten digits that are split into
            60,000 training images and 10,000 testing images.
'''
(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.mnist.load_data()

# Preprocess the data
'''
            Preprocess the data. The images are first reshaped from a 3D array (28x28 pixels)
            to a 2D array (784 pixels).
            Then, the pixel values are normalized to be between 0 and 1 by dividing by 255.
            The labels are converted to one-hot encoding format using the to_categorical()
            function provided by Keras. This is done to make it easier for the model to classify
            the images into 10 different classes (one for each digit).
'''

# Reshape and normalize training data
train_data = train_data.reshape((60000, 784)) / 255.0

# Reshape and normalize testing data
test_data = test_data.reshape((10000, 784)) / 255.0

# Convert training labels to one-hot encoding
train_labels = tf.keras.utils.to_categorical(train_labels)

# Convert testing labels to one-hot encoding
test_labels = tf.keras.utils.to_categorical(test_labels)

# Define the model architecture
'''
            This code defines the architecture of the neural network model. The Sequential ()
            function is used to create a sequential model, meaning that the layers are added in
            sequence. Three fully connected layers are defined using the Dense () function.
            The first layer has 128 units, ReLU activation, and L2 regularization with a
            regularization parameter of 0.01.
            The second layer has 64 units, ReLU activation, and L2 regularization with a
            regularization parameter of 0.01.
            The third and final layer has 10 units, softmax activation, and is used for the
            classification task.
'''

model = tf.keras.models.Sequential([ # Define sequential model
        #Add a fully connected layer with 128 units, ReLU activation, and L2 regularization
    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,),
    kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    # Add another fully connected layer with 64 units,ReLU activation, and L2 regularization
    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    # Add a final output layer with 10 units (one for each class), softmax activation
    tf.keras.layers.Dense(10, activation='softmax')
 ])

# Compile the model

'''
            This code compiles the model. The compile () function configures the model for
            training by specifying the optimizer, loss function, and metrics to monitor during
            training. In this case, the Adam optimizer is used with a learning rate of 0.001,
            categorical cross-entropy is used as the loss function, and accuracy is monitored
            during training.
'''

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    # Use Adam optimizer with learning rate 0.001
    loss='categorical_crossentropy',
    # Use categorical cross-entropy loss function
    metrics=['accuracy']) # Monitor accuracy during training

# Train the model
'''
            This code trains the model using the fit () function. The training data and labels
            are passed in as arguments, along with the number of epochs to train for, the batch
            size to use, and the validation data to use for monitoring model performance during
            training. The fit () function returns a history object that contains information
            about the training process, such as the loss and accuracy at each epoch. The purpose
            of this program is to demonstrate how to implement a neural network model for image
            classification using TensorFlow/Keras. The model uses regularization techniques to
            prevent overfitting and achieves high accuracy on the MNIST dataset.
'''

history = model.fit (train_data, train_labels, epochs=10, batch_size=128,
# Train the model for 10 epochs, using batches of size 128, and validate on the testing data at the end of each epoch
    validation_data= (test_data, test_labels))
